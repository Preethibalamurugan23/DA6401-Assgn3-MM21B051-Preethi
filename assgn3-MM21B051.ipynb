{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DA6401 - Assignment 3 - MM21B051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading and preprocessing the data\n",
    "\n",
    "th train test and dev tsv files were stored inside a folder named lexicons in kaggle during training and testing. please modify your data_dir according to your storage location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Attention, Layer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to your data directory on Kaggle\n",
    "data_dir = '/kaggle/input/lexicons/'\n",
    "\n",
    "train_df = pd.read_csv(f'{data_dir}hi.translit.sampled.train.tsv', sep='\\t', header=None, names=['native', 'romanized', 'attestation'])\n",
    "dev_df = pd.read_csv(f'{data_dir}hi.translit.sampled.dev.tsv', sep='\\t', header=None, names=['native', 'romanized', 'attestation'])\n",
    "test_df = pd.read_csv(f'{data_dir}hi.translit.sampled.test.tsv', sep='\\t', header=None, names=['native', 'romanized', 'attestation'])\n",
    "\n",
    "print(\"Train data shape:\", train_df.shape)\n",
    "print(\"Dev data shape:\", dev_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    input_texts = df['romanized'].tolist()\n",
    "    target_texts = ['<start> ' + text + ' <end>' for text in df['native'].tolist()]\n",
    "    return input_texts, target_texts\n",
    "\n",
    "input_texts_train, target_texts_train = preprocess_data(train_df)\n",
    "input_texts_train_raw, target_texts_train_raw = preprocess_data(train_df)\n",
    "\n",
    "input_texts_dev, target_texts_dev = preprocess_data(dev_df)\n",
    "input_texts_test, target_texts_test = preprocess_data(test_df)\n",
    "\n",
    "print(\"Example input (train):\", input_texts_train[0])\n",
    "print(\"Example target (train):\", target_texts_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing nan values in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Identify valid indices where input is a non-NaN string\n",
    "valid_train_indices = [i for i, text in enumerate(input_texts_train_raw) if isinstance(text, str) and not pd.isna(text)]\n",
    "\n",
    "# Filter both input and target lists using these valid indices\n",
    "input_texts_train = [input_texts_train_raw[i] for i in valid_train_indices]\n",
    "target_texts_train = [target_texts_train_raw[i] for i in valid_train_indices]\n",
    "\n",
    "print(\"Example input (train - filtered):\", input_texts_train[0])\n",
    "print(\"Example target (train - filtered):\", target_texts_train[0])\n",
    "\n",
    "# Check again if any non-string or nan values remain in input_texts_train\n",
    "non_string_inputs = [(i, text) for i, text in enumerate(input_texts_train) if not isinstance(text, str) or pd.isna(text)]\n",
    "if non_string_inputs:\n",
    "    print(\"Found remaining non-string or nan values in input_texts_train:\")\n",
    "    for index, value in non_string_inputs:\n",
    "        print(f\"Index: {index}, Type: {type(value)}, Value: {value}\")\n",
    "else:\n",
    "    print(\"No non-string or nan values found in input_texts_train after filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenizer for input (romanized)\n",
    "input_tokenizer = Tokenizer(char_level=True)\n",
    "input_tokenizer.fit_on_texts(input_texts_train)\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "input_sequences_train = input_tokenizer.texts_to_sequences(input_texts_train)\n",
    "input_sequences_dev = input_tokenizer.texts_to_sequences(input_texts_dev)\n",
    "input_sequences_test = input_tokenizer.texts_to_sequences(input_texts_test)\n",
    "\n",
    "# Tokenizer for target (native)\n",
    "target_tokenizer = Tokenizer(char_level=True)\n",
    "target_tokenizer.fit_on_texts(target_texts_train)\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "target_sequences_train = target_tokenizer.texts_to_sequences(target_texts_train)\n",
    "target_sequences_dev = target_tokenizer.texts_to_sequences(target_texts_dev)\n",
    "target_sequences_test = target_tokenizer.texts_to_sequences(target_texts_test)\n",
    "\n",
    "print(\"Input vocabulary size:\", input_vocab_size)\n",
    "print(\"Target vocabulary size:\", target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_input_len = max(len(seq) for seq in input_sequences_train)\n",
    "max_target_len = max(len(seq) for seq in target_sequences_train)\n",
    "\n",
    "encoder_input_data_train = pad_sequences(input_sequences_train, maxlen=max_input_len, padding='post')\n",
    "decoder_input_data_train = pad_sequences(target_sequences_train, maxlen=max_target_len, padding='post')\n",
    "decoder_target_data_train = np.zeros_like(decoder_input_data_train)\n",
    "for i, seq in enumerate(target_sequences_train):\n",
    "    for j in range(1, len(seq)):\n",
    "        decoder_target_data_train[i, j - 1] = seq[j] # Target is shifted by one\n",
    "\n",
    "encoder_input_data_dev = pad_sequences(input_sequences_dev, maxlen=max_input_len, padding='post')\n",
    "decoder_input_data_dev = pad_sequences(target_sequences_dev, maxlen=max_target_len, padding='post')\n",
    "decoder_target_data_dev = np.zeros_like(decoder_input_data_dev)\n",
    "for i, seq in enumerate(target_sequences_dev):\n",
    "    for j in range(1, len(seq)):\n",
    "        decoder_target_data_dev[i, j - 1] = seq[j]\n",
    "\n",
    "encoder_input_data_test = pad_sequences(input_sequences_test, maxlen=max_input_len, padding='post')\n",
    "decoder_input_data_test = pad_sequences(target_sequences_test, maxlen=max_target_len, padding='post')\n",
    "decoder_target_data_test = np.zeros_like(decoder_input_data_test)\n",
    "for i, seq in enumerate(target_sequences_test):\n",
    "    for j in range(1, len(seq)):\n",
    "        decoder_target_data_test[i, j - 1] = seq[j]\n",
    "\n",
    "print(\"Padded input data (train) shape:\", encoder_input_data_train.shape)\n",
    "print(\"Padded target input data (train) shape:\", decoder_input_data_train.shape)\n",
    "print(\"Padded target output data (train) shape:\", decoder_target_data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Defining model class nad testing a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, LSTM, GRU, Dense\n",
    "\n",
    "def build_vanilla_rnn_seq2seq(\n",
    "    input_vocab_size,\n",
    "    target_vocab_size,\n",
    "    embedding_dim,\n",
    "    encoder_units,\n",
    "    decoder_units,\n",
    "    cell_type='rnn',\n",
    "    num_encoder_layers=1,\n",
    "    num_decoder_layers=1,\n",
    "    max_input_len=None,  # Needed for the input layer shape\n",
    "    max_target_len=None  # Not strictly needed here but good for context\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds a vanilla RNN-based sequence-to-sequence model.\n",
    "\n",
    "    Args:\n",
    "        input_vocab_size (int): Size of the input character vocabulary.\n",
    "        target_vocab_size (int): Size of the target character vocabulary.\n",
    "        embedding_dim (int): Dimension of the character embeddings.\n",
    "        encoder_units (int): Number of hidden units in the encoder RNN(s).\n",
    "        decoder_units (int): Number of hidden units in the decoder RNN(s).\n",
    "        cell_type (str): Type of RNN cell to use ('rnn', 'lstm', 'gru'). Defaults to 'rnn'.\n",
    "        num_encoder_layers (int): Number of layers in the encoder RNN. Defaults to 1.\n",
    "        num_decoder_layers (int): Number of layers in the decoder RNN. Defaults to 1.\n",
    "        max_input_len (int, optional): Maximum length of the input sequences. Defaults to None.\n",
    "        max_target_len (int, optional): Maximum length of the target sequences. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The built sequence-to-sequence model.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------- Encoder ----------------\n",
    "    encoder_inputs = Input(shape=(max_input_len,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "    encoder_outputs = encoder_embedding\n",
    "    encoder_states = []\n",
    "\n",
    "    for i in range(num_encoder_layers):\n",
    "        if cell_type == 'rnn':\n",
    "            encoder_rnn = SimpleRNN(encoder_units, return_state=True, return_sequences=False, name=f'encoder_rnn_{i}')\n",
    "            encoder_outputs, state_h = encoder_rnn(encoder_outputs)\n",
    "            encoder_states.append(state_h)\n",
    "        elif cell_type == 'lstm':\n",
    "            encoder_lstm = LSTM(encoder_units, return_state=True, return_sequences=False, name=f'encoder_lstm_{i}')\n",
    "            encoder_outputs, state_h, state_c = encoder_lstm(encoder_outputs)\n",
    "            encoder_states.extend([state_h, state_c])\n",
    "        elif cell_type == 'gru':\n",
    "            encoder_gru = GRU(encoder_units, return_state=True, return_sequences=False, name=f'encoder_gru_{i}')\n",
    "            encoder_outputs, state_h = encoder_gru(encoder_outputs)\n",
    "            encoder_states.append(state_h)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cell_type. Choose from 'rnn', 'lstm', or 'gru'.\")\n",
    "\n",
    "    # The final encoder state(s) will be used to initialize the decoder\n",
    "\n",
    "    # ---------------- Decoder ----------------\n",
    "    decoder_inputs = Input(shape=(None,))  # Length of target sequence is variable\n",
    "    decoder_embedding = Embedding(target_vocab_size, embedding_dim)(decoder_inputs)\n",
    "    decoder_outputs = decoder_embedding\n",
    "\n",
    "    decoder_states = encoder_states[:num_decoder_layers * (2 if cell_type == 'lstm' else 1)] # Initialize with encoder's final states\n",
    "\n",
    "    for i in range(num_decoder_layers):\n",
    "        if cell_type == 'rnn':\n",
    "            decoder_rnn = SimpleRNN(decoder_units, return_sequences=True, return_state=True, name=f'decoder_rnn_{i}')\n",
    "            decoder_outputs, state_h = decoder_rnn(decoder_outputs, initial_state=decoder_states[i])\n",
    "            decoder_states[i] = state_h\n",
    "        elif cell_type == 'lstm':\n",
    "            decoder_lstm = LSTM(decoder_units, return_sequences=True, return_state=True, name=f'decoder_lstm_{i}')\n",
    "            decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs, initial_state=decoder_states[2*i:2*i+2])\n",
    "            decoder_states[2*i] = state_h\n",
    "            decoder_states[2*i+1] = state_c\n",
    "        elif cell_type == 'gru':\n",
    "            decoder_gru = GRU(decoder_units, return_sequences=True, return_state=True, name=f'decoder_gru_{i}')\n",
    "            decoder_outputs, state_h = decoder_gru(decoder_outputs, initial_state=decoder_states[i])\n",
    "            decoder_states[i] = state_h\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cell_type. Choose from 'rnn', 'lstm', or 'gru'.\")\n",
    "\n",
    "    # Output layer\n",
    "    decoder_dense = Dense(target_vocab_size, activation='softmax')(decoder_outputs)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
    "    return model\n",
    "\n",
    "# ---------------- Instantiate and Test the Model ----------------\n",
    "# Assuming you have the vocabulary sizes and max lengths from your preprocessing\n",
    "embedding_dim = 64\n",
    "encoder_units = 128\n",
    "decoder_units = 128\n",
    "num_encoder_layers = 1\n",
    "num_decoder_layers = 1\n",
    "cell_type = 'lstm'  # You can change this to 'rnn' or 'gru'\n",
    "\n",
    "model = build_vanilla_rnn_seq2seq(\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    encoder_units=encoder_units,\n",
    "    decoder_units=decoder_units,\n",
    "    cell_type=cell_type,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    max_input_len=max_input_len,\n",
    "    max_target_len=max_target_len\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Wandb and Sweep across hyper-parameters\n",
    "please replace the key below with your wandb key while running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T20:10:38.924665Z",
     "iopub.status.busy": "2025-05-20T20:10:38.924013Z",
     "iopub.status.idle": "2025-05-20T20:10:53.200770Z",
     "shell.execute_reply": "2025-05-20T20:10:53.200185Z",
     "shell.execute_reply.started": "2025-05-20T20:10:38.924642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmm21b051\u001b[0m (\u001b[33mmm21b051-iitmaana\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "!pip install wandb -q\n",
    "wandb.login(key = \"39ded67ba2685c0f85010b40d27298a712244e64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'program': 'your_kaggle_notebook.ipynb',  # Replace with your notebook name\n",
    "    'method': 'bayes',  # Or 'grid', 'random'\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'embedding_dim': {\n",
    "            'values': [16, 32, 64, 128, 256]\n",
    "        },\n",
    "        'num_encoder_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'num_decoder_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'decoder_units': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['gru']\n",
    "        },\n",
    "        'dropout_rate': {\n",
    "            'values': [0.0, 0.2]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'rmsprop']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.001, 0.0001]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64, 128]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "class ExpandDims(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(ExpandDims, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.expand_dims(inputs, axis=self.axis)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'axis': self.axis})\n",
    "        return config\n",
    "\n",
    "def build_and_train_model(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        # ---------------- Encoder ----------------\n",
    "        encoder_inputs = Input(shape=(max_input_len,))\n",
    "        encoder_embedding = Embedding(input_vocab_size, config.embedding_dim)(encoder_inputs)\n",
    "        encoder_outputs = encoder_embedding\n",
    "        encoder_states = []\n",
    "        encoder_units = config.decoder_units\n",
    "        encoder_final_state = None\n",
    "\n",
    "        for i in range(config.num_encoder_layers):\n",
    "            if config.cell_type == 'rnn':\n",
    "                encoder_rnn = SimpleRNN(encoder_units, return_state=True, return_sequences=True, name=f'encoder_rnn_{i}')\n",
    "            elif config.cell_type == 'lstm':\n",
    "                encoder_rnn = LSTM(encoder_units, return_state=True, return_sequences=True, name=f'encoder_lstm_{i}')\n",
    "            elif config.cell_type == 'gru':\n",
    "                encoder_rnn = GRU(encoder_units, return_state=True, return_sequences=True, name=f'encoder_gru_{i}')\n",
    "\n",
    "            encoder_outputs, *state = encoder_rnn(encoder_outputs)\n",
    "            if config.dropout_rate > 0:\n",
    "                encoder_outputs = Dropout(config.dropout_rate)(encoder_outputs)\n",
    "            encoder_states.append(state)\n",
    "            encoder_final_state = state\n",
    "\n",
    "        if config.cell_type == 'gru':\n",
    "            encoder_final_state = encoder_final_state[0]\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        decoder_inputs = Input(shape=(None,))\n",
    "        decoder_embedding = Embedding(target_vocab_size, config.embedding_dim)(decoder_inputs)\n",
    "        decoder_outputs = decoder_embedding\n",
    "        # Wrap tf.expand_dims in a Keras Layer\n",
    "        expand_dims_layer = ExpandDims(axis=0)\n",
    "        decoder_initial_state = expand_dims_layer(encoder_final_state)\n",
    "        decoder_all_states = []\n",
    "\n",
    "        for i in range(config.num_decoder_layers):\n",
    "            if config.cell_type == 'rnn':\n",
    "                decoder_rnn = SimpleRNN(config.decoder_units, return_sequences=True, return_state=True, name=f'decoder_rnn_{i}')\n",
    "            elif config.cell_type == 'lstm':\n",
    "                decoder_rnn = LSTM(config.decoder_units, return_sequences=True, return_state=True, name=f'decoder_lstm_{i}')\n",
    "            elif config.cell_type == 'gru':\n",
    "                decoder_rnn = GRU(config.decoder_units, return_sequences=True, return_state=True, name=f'decoder_gru_{i}')\n",
    "\n",
    "            decoder_outputs, *state = decoder_rnn(decoder_outputs, initial_state=decoder_initial_state if i == 0 else decoder_all_states[-1])\n",
    "            if config.dropout_rate > 0:\n",
    "                decoder_outputs = Dropout(config.dropout_rate)(decoder_outputs)\n",
    "            decoder_all_states.append(state[0] if config.cell_type in ['lstm', 'gru'] else state)\n",
    "            if i > 0:\n",
    "                decoder_initial_state = decoder_all_states[-1]\n",
    "\n",
    "        decoder_dense = Dense(target_vocab_size, activation='softmax')(decoder_outputs)\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
    "\n",
    "        if config.optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=config.learning_rate)\n",
    "        elif config.optimizer == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=config.learning_rate)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Prepare target data for training (teacher forcing)\n",
    "        decoder_input_train = decoder_input_data_train[:, :-1]\n",
    "        decoder_target_train = decoder_target_data_train[:, 1:]\n",
    "        decoder_target_train_one_hot = tf.one_hot(decoder_target_train, depth=target_vocab_size)\n",
    "\n",
    "        # Prepare validation data similarly\n",
    "        decoder_input_dev = decoder_input_data_dev[:, :-1]\n",
    "        decoder_target_dev = decoder_target_data_dev[:, 1:]\n",
    "        decoder_target_dev_one_hot = tf.one_hot(decoder_target_dev, depth=target_vocab_size)\n",
    "\n",
    "        # Print shapes before fitting\n",
    "        print(\"Encoder input data shape:\", encoder_input_data_train.shape)\n",
    "        print(\"Decoder input train shape:\", decoder_input_train.shape)\n",
    "        print(\"Decoder target train one-hot shape:\", decoder_target_train_one_hot.shape)\n",
    "        print(\"Decoder input dev shape:\", decoder_input_dev.shape)\n",
    "        print(\"Decoder target dev one-hot shape:\", decoder_target_dev_one_hot.shape)\n",
    "\n",
    "\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger(log_freq='epoch'),\n",
    "            WandbModelCheckpoint(\n",
    "                filepath=\"best_model_{epoch:02d}-{val_accuracy:.4f}.h5\",\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        history = model.fit(\n",
    "            [encoder_input_data_train, decoder_input_train],\n",
    "            decoder_target_train_one_hot,\n",
    "            batch_size=config.batch_size,\n",
    "            epochs=10,\n",
    "            validation_data=(\n",
    "                [encoder_input_data_dev, decoder_input_dev],\n",
    "                decoder_target_dev_one_hot\n",
    "            ),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Initialize WandB and run the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"dakshina-transliteration\")\n",
    "wandb.agent(sweep_id, build_and_train_model, count=50) # Adjust the 'count' for the number of runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training again and testing on the model with best configs from sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "# --- Best configuration from your sweep ---\n",
    "best_config = {\n",
    "    'batch_size': 64,\n",
    "    'cell_type': 'lstm',\n",
    "    'decoder_units': 128,\n",
    "    'dropout_rate': 0.2,\n",
    "    'embedding_dim': 64,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_decoder_layers': 2,\n",
    "    'num_encoder_layers': 1,\n",
    "    'optimizer': 'adam'\n",
    "}\n",
    "\n",
    "class ExpandDims(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(ExpandDims, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.expand_dims(inputs, axis=self.axis)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'axis': self.axis})\n",
    "        return config\n",
    "\n",
    "def build_and_train_model(config):\n",
    "    # ---------------- Encoder ----------------\n",
    "    encoder_inputs = Input(shape=(max_input_len,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, config['embedding_dim'])(encoder_inputs)\n",
    "    encoder_outputs = encoder_embedding\n",
    "    encoder_states = []\n",
    "    encoder_units = config['decoder_units']\n",
    "    encoder_final_state = None\n",
    "\n",
    "    for i in range(config['num_encoder_layers']):\n",
    "        if config['cell_type'] == 'rnn':\n",
    "            encoder_rnn = SimpleRNN(encoder_units, return_state=True, return_sequences=True, name=f'encoder_rnn_{i}')\n",
    "        elif config['cell_type'] == 'lstm':\n",
    "            encoder_rnn = LSTM(encoder_units, return_state=True, return_sequences=True, name=f'encoder_lstm_{i}')\n",
    "        elif config['cell_type'] == 'gru':\n",
    "            encoder_rnn = GRU(encoder_units, return_state=True, return_sequences=True, name=f'encoder_gru_{i}')\n",
    "\n",
    "        encoder_outputs, *state = encoder_rnn(encoder_outputs)\n",
    "        if config['dropout_rate'] > 0:\n",
    "            encoder_outputs = Dropout(config['dropout_rate'])(encoder_outputs)\n",
    "        encoder_states.append(state)\n",
    "        encoder_final_state = state\n",
    "\n",
    "    if config['cell_type'] == 'gru':\n",
    "        encoder_final_state = encoder_final_state[0]\n",
    "    elif config['cell_type'] == 'lstm':\n",
    "        encoder_final_state = encoder_final_state  # Keep both h and c states\n",
    "\n",
    "    # ---------------- Decoder ----------------\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    decoder_embedding = Embedding(target_vocab_size, config['embedding_dim'])(decoder_inputs)\n",
    "    decoder_outputs = decoder_embedding\n",
    "    decoder_initial_state = encoder_final_state\n",
    "    decoder_all_states = []\n",
    "\n",
    "    for i in range(config['num_decoder_layers']):\n",
    "        if config['cell_type'] == 'rnn':\n",
    "            decoder_rnn = SimpleRNN(config['decoder_units'], return_sequences=True, return_state=True, name=f'decoder_rnn_{i}')\n",
    "        elif config['cell_type'] == 'lstm':\n",
    "            decoder_rnn = LSTM(config['decoder_units'], return_sequences=True, return_state=True, name=f'decoder_lstm_{i}')\n",
    "        elif config['cell_type'] == 'gru':\n",
    "            decoder_rnn = GRU(config['decoder_units'], return_sequences=True, return_state=True, name=f'decoder_gru_{i}')\n",
    "\n",
    "        decoder_outputs, *state = decoder_rnn(decoder_outputs, initial_state=decoder_initial_state if i == 0 else decoder_all_states[-1])\n",
    "        if config['dropout_rate'] > 0:\n",
    "            decoder_outputs = Dropout(config['dropout_rate'])(decoder_outputs)\n",
    "        decoder_all_states.append(state)\n",
    "        if i > 0:\n",
    "            decoder_initial_state = state\n",
    "\n",
    "    decoder_dense = Dense(target_vocab_size, activation='softmax')(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
    "\n",
    "    optimizer_name = config['optimizer'].lower()\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=config['learning_rate'])\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=config['learning_rate'])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Prepare target data for training (teacher forcing)\n",
    "decoder_input_train = decoder_input_data_train[:, :-1]\n",
    "decoder_target_train = decoder_target_data_train[:, 1:]\n",
    "decoder_target_train_one_hot = tf.one_hot(decoder_target_train, depth=target_vocab_size)\n",
    "\n",
    "# Prepare validation data similarly\n",
    "decoder_input_dev = decoder_input_data_dev[:, :-1]\n",
    "decoder_target_dev = decoder_target_data_dev[:, 1:]\n",
    "decoder_target_dev_one_hot = tf.one_hot(decoder_target_dev, depth=target_vocab_size)\n",
    "\n",
    "decoder_input_test = decoder_input_data_test[:, :-1]\n",
    "decoder_target_test = decoder_target_data_test[:, 1:]\n",
    "decoder_target_test_one_hot = tf.one_hot(decoder_target_test, depth=target_vocab_size)\n",
    "\n",
    "\n",
    "# --- Build and train the best model ---\n",
    "tf.config.list_physical_devices('GPU') # Ensure GPUs are visible\n",
    "with tf.device('/GPU:0'): # Train on the first GPU (you can adjust this)\n",
    "    best_model = build_and_train_model(best_config)\n",
    "\n",
    "    history = best_model.fit(\n",
    "            [encoder_input_data_train, decoder_input_train],\n",
    "            decoder_target_train_one_hot,\n",
    "            batch_size=best_config['batch_size'],\n",
    "            epochs=10,\n",
    "            validation_data=(\n",
    "                [encoder_input_data_dev, decoder_input_dev],\n",
    "                decoder_target_dev_one_hot\n",
    "            ),\n",
    "            callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)] # Added EarlyStopping\n",
    "        )\n",
    "    print(\"Best model trained.\")\n",
    "\n",
    "decoder_target_test_one_hot = tf.one_hot(decoder_target_test, depth=target_vocab_size)\n",
    "\n",
    "# --- Evaluate the best model on the test set ---\n",
    "loss, accuracy = best_model.evaluate(\n",
    "    [encoder_input_data_test, decoder_input_test[:, :-1]],\n",
    "    decoder_target_test_one_hot[:, 1:],\n",
    "    batch_size=best_config['batch_size'],\n",
    "    verbose=0\n",
    ")\n",
    "print(f\"\\nTest Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# --- Prediction Function (Adjusted for the trained model) ---\n",
    "def translate_sentence(input_sequence, model, input_tokenizer, target_tokenizer, max_target_len, config):\n",
    "    encoder_inputs = model.input[0]\n",
    "    encoder_embedding_layer = model.get_layer(index=1) # Assuming embedding is the second layer\n",
    "    encoder_output_layer = [layer for layer in model.layers if 'encoder' in layer.name and isinstance(layer, (SimpleRNN, LSTM, GRU))][-1] # Get the last encoder RNN layer\n",
    "\n",
    "    encoder_model = tf.keras.Model(encoder_inputs, encoder_output_layer.output) # Output sequences\n",
    "\n",
    "    decoder_inputs = model.input[1]\n",
    "    decoder_embedding_layer = [layer for layer in model.layers if 'embedding' in layer.name and layer.input is decoder_inputs][0]\n",
    "    decoder_rnn_layers = [layer for layer in model.layers if 'decoder' in layer.name and isinstance(layer, (SimpleRNN, LSTM, GRU))]\n",
    "    decoder_dense_layer = [layer for layer in model.layers if isinstance(layer, Dense) and layer.output_shape[-1] == target_vocab_size][0]\n",
    "\n",
    "    # Reconstruct the decoder model for prediction\n",
    "    decoder_state_input = [tf.keras.layers.Input(shape=(config['decoder_units'],), name=f'decoder_in_{i}') for i in range(len(decoder_rnn_layers) * (1 if config['cell_type'] in ['rnn', 'gru'] else 2))]\n",
    "    decoder_embedding_out = decoder_embedding_layer(decoder_inputs)\n",
    "    decoder_outputs = decoder_embedding_out\n",
    "    decoder_states = decoder_state_input\n",
    "\n",
    "    next_decoder_states = []\n",
    "    for i, rnn_layer in enumerate(decoder_rnn_layers):\n",
    "        if config['cell_type'] == 'lstm':\n",
    "            decoder_outputs, state_h, state_c = rnn_layer(decoder_outputs, initial_state=[decoder_states[i*2], decoder_states[i*2+1]])\n",
    "            next_decoder_states.extend([state_h, state_c])\n",
    "        else:\n",
    "            decoder_outputs, state = rnn_layer(decoder_outputs, initial_state=[decoder_states[i]])\n",
    "            next_decoder_states.append(state)\n",
    "\n",
    "    decoder_outputs = decoder_dense_layer(decoder_outputs)\n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_state_input, [decoder_outputs] + next_decoder_states)\n",
    "\n",
    "\n",
    "    # Prediction process\n",
    "    input_seq = tf.expand_dims(input_sequence, 0)\n",
    "    encoder_out = encoder_model.predict(input_seq)\n",
    "\n",
    "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
    "    decoder_states_val = [tf.zeros((1, config['decoder_units'])) for _ in range(len(decoder_rnn_layers) * (1 if config['cell_type'] in ['rnn', 'gru'] else 2))] # Initialize with zeros\n",
    "\n",
    "    if config['cell_type'] == 'lstm':\n",
    "        # Initialize LSTM states with encoder output (assuming compatible shape)\n",
    "        for i in range(config['num_decoder_layers']):\n",
    "            decoder_states_val[i*2] = encoder_out[1][0] # h state\n",
    "            decoder_states_val[i*2+1] = encoder_out[2][0] # c state\n",
    "    else: # GRU or RNN\n",
    "        for i in range(config['num_decoder_layers']):\n",
    "            decoder_states_val[i] = encoder_out[1][0]\n",
    "\n",
    "\n",
    "    decoded_sentence = []\n",
    "    for _ in range(max_target_len):\n",
    "        decoder_outputs, *states = decoder_model.predict([decoder_input] + decoder_states_val)\n",
    "        predicted_id = np.argmax(decoder_outputs[0, -1, :])\n",
    "        predicted_char = target_tokenizer.index_word.get(predicted_id)\n",
    "\n",
    "        if predicted_char == '<end>':\n",
    "            break\n",
    "        if predicted_char:\n",
    "            decoded_sentence.append(predicted_char)\n",
    "\n",
    "        decoder_input = tf.expand_dims([predicted_id], 0)\n",
    "        decoder_states_val = list(states)\n",
    "\n",
    "    return ' '.join(decoded_sentence)\n",
    "\n",
    "# --- Generate and Save All Test Set Predictions ---\n",
    "predictions_folder = \"predictions_vanilla\"\n",
    "os.makedirs(predictions_folder, exist_ok=True)\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(len(encoder_input_data_test)):\n",
    "    input_sequence = encoder_input_data_test[i]\n",
    "    predicted_translation = translate_sentence(\n",
    "        input_sequence,\n",
    "        best_model,\n",
    "        input_tokenizer,\n",
    "        target_tokenizer,\n",
    "        max_target_len,\n",
    "        best_config\n",
    "    )\n",
    "    all_predictions.append(predicted_translation)\n",
    "    filename = os.path.join(predictions_folder, f\"prediction_{i}.txt\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(predicted_translation)\n",
    "\n",
    "print(f\"\\nAll test set predictions saved to '{predictions_folder}'.\")\n",
    "\n",
    "# --- Sample Inputs and Predictions (Creative Grid) ---\n",
    "num_samples_to_show = 5\n",
    "sample_indices = np.random.choice(len(encoder_input_data_test), size=num_samples_to_show, replace=False)\n",
    "\n",
    "print(\"\\n--- Sample Test Inputs and Predictions ---\")\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(f\"{'Input':<20} | {'Predicted':<20} | {'Reference':<20}\")\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "for index in sample_indices:\n",
    "    input_sequence = encoder_input_data_test[index]\n",
    "    predicted_translation = translate_sentence(\n",
    "        input_sequence,\n",
    "        best_model,\n",
    "        input_tokenizer,\n",
    "        target_tokenizer,\n",
    "        max_target_len,\n",
    "        best_config\n",
    "    )\n",
    "\n",
    "    reference_tokens = [target_tokenizer.index_word.get(i, '<unk>') for i in decoder_target_test[index] if i != 0]\n",
    "    reference_translation = ' '.join(reference_tokens).replace('<start>', '').replace('<end>', '').strip()\n",
    "\n",
    "    input_tokens = [input_tokenizer.index_word.get(i, '<unk>') for i in input_sequence if i != 0]\n",
    "    input_text = ' '.join(input_tokens)\n",
    "\n",
    "    print(f\"{input_text[:20]:<20} | {predicted_translation[:20]:<20} | {reference_translation[:20]:<20}\")\n",
    "\n",
    "print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: define the attention based model and sweep across hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Attention, Concatenate, Layer\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "class ReshapeInitialState(Layer):\n",
    "    def __init__(self, target_shape, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.reshape(inputs, self.target_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'target_shape': self.target_shape})\n",
    "        return config\n",
    "\n",
    "def build_and_train_model(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        # ---------------- Encoder ----------------\n",
    "        encoder_inputs = Input(shape=(max_input_len,))\n",
    "        encoder_embedding = Embedding(input_vocab_size, config.embedding_dim)(encoder_inputs)\n",
    "        encoder_outputs = encoder_embedding # Initialize encoder_outputs\n",
    "\n",
    "        if config.cell_type == 'lstm':\n",
    "            encoder_outputs, encoder_state_h, encoder_state_c = LSTM(config.encoder_units, return_sequences=True, return_state=True, name='encoder_lstm_0')(encoder_outputs)\n",
    "            encoder_states = [encoder_state_h, encoder_state_c]\n",
    "        elif config.cell_type == 'gru':\n",
    "            encoder_outputs, encoder_state = GRU(config.encoder_units, return_sequences=True, return_state=True, name='encoder_gru_0')(encoder_outputs)\n",
    "            encoder_states = [encoder_state]\n",
    "        else:  # SimpleRNN\n",
    "            encoder_outputs, encoder_state = SimpleRNN(config.encoder_units, return_sequences=True, return_state=True, name='encoder_rnn_0')(encoder_embedding)\n",
    "            encoder_states = [encoder_state]\n",
    "\n",
    "        if config.dropout_rate > 0:\n",
    "            encoder_outputs = Dropout(config.dropout_rate)(encoder_outputs)\n",
    "\n",
    "        # ---------------- Decoder ----------------\n",
    "        decoder_inputs = Input(shape=(None,))\n",
    "        decoder_embedding = Embedding(target_vocab_size, config.embedding_dim)(decoder_inputs)\n",
    "        decoder_outputs = decoder_embedding # Initialize decoder_outputs\n",
    "\n",
    "        if config.cell_type == 'lstm':\n",
    "            decoder_lstm = LSTM(config.decoder_units, return_sequences=True, return_state=True, name='decoder_lstm_0')\n",
    "        elif config.cell_type == 'gru':\n",
    "            decoder_gru = GRU(config.decoder_units, return_sequences=True, return_state=True, name='decoder_gru_0')\n",
    "        else:  # SimpleRNN\n",
    "            decoder_rnn = SimpleRNN(config.decoder_units, return_sequences=True, return_state=True, name='decoder_rnn_0')\n",
    "\n",
    "        # Initial decoder state is the final encoder state\n",
    "        decoder_initial_state = encoder_states\n",
    "        if config.cell_type == 'gru':\n",
    "            decoder_initial_state = [ReshapeInitialState((-1, config.decoder_units))(state) for state in decoder_initial_state] # Ensure correct shape for GRU\n",
    "\n",
    "        # Apply the decoder RNN\n",
    "        if config.cell_type == 'lstm':\n",
    "            decoder_outputs, _, _ = decoder_lstm(decoder_outputs, initial_state=decoder_initial_state)\n",
    "        else:\n",
    "            decoder_outputs, _ = (decoder_gru if config.cell_type == 'gru' else decoder_rnn)(decoder_outputs, initial_state=decoder_initial_state)\n",
    "\n",
    "        if config.dropout_rate > 0:\n",
    "            decoder_outputs = Dropout(config.dropout_rate)(decoder_outputs)\n",
    "\n",
    "        # ---------------- Attention Mechanism ----------------\n",
    "        attention = Attention()([decoder_outputs, encoder_outputs])\n",
    "        context_vector = attention\n",
    "\n",
    "        # Concatenate the context vector with the decoder output\n",
    "        decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, context_vector])\n",
    "\n",
    "        # Final dense layer\n",
    "        decoder_dense = Dense(target_vocab_size, activation='softmax')(decoder_concat_input)\n",
    "\n",
    "        # Define the model\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
    "\n",
    "        if config.optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=config.learning_rate)\n",
    "        elif config.optimizer == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=config.learning_rate)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Prepare target data for training (teacher forcing)\n",
    "        decoder_input_train = decoder_input_data_train[:, :-1]\n",
    "        decoder_target_train = decoder_target_data_train[:, 1:]\n",
    "        decoder_target_train_one_hot = tf.one_hot(decoder_target_train, depth=target_vocab_size, axis=-1) # Use axis=-1\n",
    "\n",
    "        decoder_input_dev = decoder_input_data_dev[:, :-1]\n",
    "        decoder_target_dev = decoder_target_data_dev[:, 1:]\n",
    "        decoder_target_dev_one_hot = tf.one_hot(decoder_target_dev, depth=target_vocab_size, axis=-1) # Use axis=-1\n",
    "\n",
    "        # Print shapes before fitting\n",
    "        print(\"Encoder input data shape:\", encoder_input_data_train.shape)\n",
    "        print(\"Decoder input train shape:\", decoder_input_train.shape)\n",
    "        print(\"Decoder target train one-hot shape:\", decoder_target_train_one_hot.shape)\n",
    "        print(\"Decoder input dev shape:\", decoder_input_data_dev.shape)\n",
    "        print(\"Decoder target dev one-hot shape:\", decoder_target_dev_one_hot.shape)\n",
    "\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger(log_freq='epoch'),\n",
    "            WandbModelCheckpoint(\n",
    "                filepath=\"attention_best_model_{epoch:02d}-{val_accuracy:.4f}.h5\",\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            [encoder_input_data_train, decoder_input_train],\n",
    "            decoder_target_train_one_hot,\n",
    "            batch_size=config.batch_size,\n",
    "            epochs=config.epochs,\n",
    "            validation_data=(\n",
    "                [encoder_input_data_dev, decoder_input_dev],\n",
    "                decoder_target_dev_one_hot\n",
    "            ),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        return history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define your sweep configuration for the attention model\n",
    "    attention_sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {\n",
    "            'name': 'val_accuracy',\n",
    "            'goal': 'maximize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'embedding_dim': {'values': [128, 256]},\n",
    "            'encoder_units': {'values': [128, 256]},\n",
    "            'decoder_units': {'values': [128, 256]},\n",
    "            'dropout_rate': {'values': [0.0, 0.2]},\n",
    "            'cell_type': {'values': ['lstm']}, # Let's focus on LSTM and GRU for attention\n",
    "            'optimizer': {'values': ['adam', 'rmsprop']},\n",
    "            'learning_rate': {'values': [1e-3, 1e-4]},\n",
    "            'batch_size': {'values': [64, 128]},\n",
    "            'epochs': {'value': 10} # Set a fixed number of epochs for this sweep\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Initialize the sweep for the attention model\n",
    "    attention_sweep_id = wandb.sweep(attention_sweep_config, project=\"dakshina-transliteration-attention\", entity=\"mm21b051-iitmaana\")\n",
    "\n",
    "    # Run the WandB agent to start the sweep\n",
    "    wandb.agent(attention_sweep_id, function=build_and_train_model,count=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing best attention based model and generating heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Attention, Concatenate, Layer\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the ReshapeInitialState layer\n",
    "class ReshapeInitialState(Layer):\n",
    "    def __init__(self, target_shape, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.reshape(inputs, self.target_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'target_shape': self.target_shape})\n",
    "        return config\n",
    "\n",
    "def build_and_train_model(config, encoder_input_data_train, decoder_input_data_train, decoder_target_data_train,\n",
    "                          encoder_input_data_dev, decoder_input_data_dev, decoder_target_data_dev):\n",
    "    with tf.device('/GPU:0'): # Ensure training happens on GPU\n",
    "        encoder_inputs = Input(shape=(max_input_len,))\n",
    "        encoder_embedding = Embedding(input_vocab_size, config['embedding_dim'])(encoder_inputs)\n",
    "\n",
    "        if config['cell_type'] == 'lstm':\n",
    "            encoder_outputs, encoder_state_h, encoder_state_c = LSTM(config['encoder_units'], return_sequences=True, return_state=True, name='encoder_lstm_0')(encoder_embedding)\n",
    "            encoder_states = [encoder_state_h, encoder_state_c]\n",
    "        elif config['cell_type'] == 'gru':\n",
    "            encoder_outputs, encoder_state = GRU(config['encoder_units'], return_sequences=True, return_state=True, name='encoder_gru_0')(encoder_embedding)\n",
    "            encoder_states = [encoder_state]\n",
    "        else:\n",
    "            encoder_outputs, encoder_state = SimpleRNN(config['encoder_units'], return_sequences=True, return_state=True, name='encoder_rnn_0')(encoder_embedding)\n",
    "            encoder_states = [encoder_state]\n",
    "\n",
    "        if config['dropout_rate'] > 0:\n",
    "            encoder_outputs = Dropout(config['dropout_rate'])(encoder_outputs)\n",
    "\n",
    "        decoder_inputs = Input(shape=(None,))\n",
    "        decoder_embedding = Embedding(target_vocab_size, config['embedding_dim'])(decoder_inputs)\n",
    "\n",
    "        if config['cell_type'] == 'lstm':\n",
    "            decoder_lstm = LSTM(config['decoder_units'], return_sequences=True, return_state=True, name='decoder_lstm_0')\n",
    "        elif config['cell_type'] == 'gru':\n",
    "            decoder_gru = GRU(config['decoder_units'], return_sequences=True, return_state=True, name='decoder_gru_0')\n",
    "        else:\n",
    "            decoder_rnn = SimpleRNN(config['decoder_units'], return_sequences=True, return_state=True, name='encoder_rnn_0')(decoder_embedding)\n",
    "\n",
    "        decoder_initial_state = encoder_states\n",
    "        if config['cell_type'] == 'gru':\n",
    "            decoder_initial_state = [ReshapeInitialState((-1, config['decoder_units']))(state) for state in decoder_initial_state]\n",
    "\n",
    "        decoder_outputs = decoder_embedding\n",
    "\n",
    "        if config['cell_type'] == 'lstm':\n",
    "            decoder_outputs, _, _ = decoder_lstm(decoder_outputs, initial_state=decoder_initial_state)\n",
    "        else:\n",
    "            decoder_outputs, _ = (decoder_gru if config['cell_type'] == 'gru' else decoder_rnn)(decoder_outputs, initial_state=decoder_initial_state)\n",
    "\n",
    "        if config['dropout_rate'] > 0:\n",
    "            decoder_outputs = Dropout(config['dropout_rate'])(decoder_outputs)\n",
    "\n",
    "        attention = Attention(name='attention_layer')([decoder_outputs, encoder_outputs])\n",
    "        context_vector = attention\n",
    "\n",
    "        decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, context_vector])\n",
    "        decoder_dense = Dense(target_vocab_size, activation='softmax')(decoder_concat_input)\n",
    "\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
    "\n",
    "        if config['optimizer'] == 'adam':\n",
    "            optimizer = Adam(learning_rate=config['learning_rate'])\n",
    "        elif config['optimizer'] == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=config['learning_rate'])\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Prepare target data for training (teacher forcing)\n",
    "        decoder_input_train = decoder_input_data_train[:, :-1]\n",
    "        decoder_target_train = decoder_target_data_train[:, 1:]\n",
    "        decoder_target_train_one_hot = tf.one_hot(decoder_target_train, depth=target_vocab_size, axis=-1)\n",
    "\n",
    "        decoder_input_dev = decoder_input_data_dev[:, :-1]\n",
    "        decoder_target_dev = decoder_target_data_dev[:, 1:]\n",
    "        decoder_target_dev_one_hot = tf.one_hot(decoder_target_dev, depth=target_vocab_size, axis=-1)\n",
    "\n",
    "        print(\"Encoder input data shape:\", encoder_input_data_train.shape)\n",
    "        print(\"Decoder input train shape:\", decoder_input_train.shape)\n",
    "        print(\"Decoder target train one-hot shape:\", decoder_target_train_one_hot.shape)\n",
    "        print(\"Decoder input dev shape:\", decoder_input_data_dev.shape)\n",
    "        print(\"Decoder target dev one-hot shape:\", decoder_target_dev_one_hot.shape)\n",
    "\n",
    "        history = model.fit(\n",
    "            [encoder_input_data_train, decoder_input_train],\n",
    "            decoder_target_train_one_hot,\n",
    "            batch_size=config['batch_size'],\n",
    "            epochs=10, # You can adjust the number of epochs as needed\n",
    "            validation_data=(\n",
    "                [encoder_input_data_dev, decoder_input_dev],\n",
    "                decoder_target_dev_one_hot\n",
    "            ),\n",
    "            verbose=1\n",
    "        )\n",
    "        return model, history\n",
    "\n",
    "def decode_sequence(input_seq, encoder_model, decoder_model, target_vocab_inv, max_decoder_seq_length):\n",
    "    with tf.device('/GPU:0'): # Ensure inference happens on GPU\n",
    "        # Encode the input sequence to get the encoder state vector.\n",
    "        encoder_outputs = encoder_model.predict(input_seq)\n",
    "\n",
    "        # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        # Populate the first character of target sequence with the start character.\n",
    "        target_seq[0, 0] = target_vocab['<start>']\n",
    "\n",
    "        # Sampling loop for a batch of sequences\n",
    "        # (to simplify, here we assume a batch of size 1).\n",
    "        stop_condition = False\n",
    "        decoded_sentence = ''\n",
    "        attention_weights_list = []  # Store attention weights\n",
    "\n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c, attention_weights = decoder_model.predict([target_seq, encoder_outputs])\n",
    "            attention_weights_list.append(attention_weights) #append attention weights\n",
    "\n",
    "            # Sample a token.\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = target_vocab_inv[sampled_token_index]\n",
    "            decoded_sentence += sampled_char\n",
    "\n",
    "            # Exit condition: either hit max length\n",
    "            # or find stop character.\n",
    "            if (sampled_char == '<end>' or\n",
    "               len(decoded_sentence) > max_decoder_seq_length):\n",
    "                stop_condition = True\n",
    "\n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        return decoded_sentence, attention_weights_list\n",
    "\n",
    "def visualize_attention(input_text, predicted_text, attention_weights_list, input_tokens, target_tokens):\n",
    "    \"\"\"\n",
    "    Visualizes attention weights for a given input-output pair.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The original input text.\n",
    "        predicted_text (str): The predicted output text.\n",
    "        attention_weights_list (list of numpy arrays): Attention weights for each decoder step.\n",
    "        input_tokens (list): List of input tokens\n",
    "        target_tokens (list): List of target tokens\n",
    "    \"\"\"\n",
    "    # Remove <start> and <end> from target tokens and predicted text\n",
    "    target_tokens = target_tokens[1:-1]\n",
    "    predicted_text = predicted_text.replace(\"<start>\", \"\").replace(\"<end>\", \"\")\n",
    "    attention_weights_list = attention_weights_list[:len(predicted_text)] # Truncate attention weights to the length of the predicted text.\n",
    "\n",
    "    # Ensure the predicted text and attention weights list have the same length.\n",
    "    min_length = min(len(predicted_text), len(attention_weights_list))\n",
    "    predicted_text = predicted_text[:min_length]\n",
    "    attention_weights_list = attention_weights_list[:min_length]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    attention_matrix = np.array([aw[0][0] for aw in attention_weights_list])\n",
    "    # Use predicted text and input text for labels\n",
    "    sns.heatmap(attention_matrix, xticklabels=input_tokens, yticklabels=list(predicted_text), cmap='viridis')\n",
    "    plt.xlabel('Input Tokens')\n",
    "    plt.ylabel('Predicted Tokens')\n",
    "    plt.title(f'Attention Heatmap for Input: \"{input_text}\"\\nPredicted: \"{predicted_text}\"')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  \n",
    "    # 1. Define the best parameters\n",
    "    best_params = {\n",
    "        'batch_size': 64,\n",
    "        'cell_type': 'lstm',\n",
    "        'decoder_units': 256,\n",
    "        'dropout_rate': 0.2,\n",
    "        'embedding_dim': 128,\n",
    "        'encoder_units': 256,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'adam'\n",
    "    }\n",
    "    reverse_input_char_index = {v: k for k, v in input_tokenizer.word_index.items()}\n",
    "    target_vocab = {v: k for k, v in target_tokenizer.word_index.items()}\n",
    "\n",
    "    target_start_token_index = target_tokenizer.word_index.get('<start>', None)\n",
    "    target_end_token_index = target_tokenizer.word_index.get('<end>', None)\n",
    "\n",
    "    target_vocab_inv = {index: char for char, index in target_vocab.items()}\n",
    "\n",
    "\n",
    "    # 2. Build and train the model with the best parameters\n",
    "    model, history = build_and_train_model(best_params, encoder_input_data_train, decoder_input_data_train, decoder_target_data_train,\n",
    "                                          encoder_input_data_dev, decoder_input_data_dev, decoder_target_data_dev)\n",
    "\n",
    "    # 3. Prepare data for testing\n",
    "    decoder_input_test = decoder_input_data_test[:, :-1] #shape (num_samples, max_decoder_len - 1)\n",
    "    decoder_target_test = decoder_target_data_test[:, 1:]  # shape (num_samples, max_decoder_len - 1)\n",
    "    decoder_target_test_one_hot = tf.one_hot(decoder_target_test, depth=target_vocab_size, axis=-1) #shape (num_samples, max_decoder_len - 1, target_vocab_size)\n",
    "\n",
    "    # 4. Make predictions on the test set\n",
    "    with tf.device('/GPU:0'): # Ensure inference happens on GPU\n",
    "        encoder_model = Model(model.input[0], model.layers[6].output) # Encoder model\n",
    "        decoder_model = Model(\n",
    "            [model.input[1], model.layers[6].output],  # decoder_inputs, encoder_outputs\n",
    "            [model.layers[10].output, model.layers[14].output[0], model.layers[14].output[1], model.layers[11].output]) # decoder_dense, decoder_state_h, decoder_state_c, attention_weights\n",
    "\n",
    "        predictions = []\n",
    "        attention_weights = []\n",
    "        input_texts = []\n",
    "        target_texts = []\n",
    "        input_tokens_list = []\n",
    "        target_tokens_list = []\n",
    "\n",
    "        for i in range(len(encoder_input_data_test)):\n",
    "            input_seq = encoder_input_data_test[i:i+1]\n",
    "            decoded_sentence, attention_weights_list = decode_sequence(input_seq, encoder_model, decoder_model, target_vocab_inv, max_decoder_len)\n",
    "            predictions.append(decoded_sentence)\n",
    "            attention_weights.append(attention_weights_list)\n",
    "\n",
    "            #get input and target text for visualization\n",
    "            input_text = ''.join([target_vocab_inv[idx] for idx in encoder_input_data_test[i] if idx != 0 and idx != target_vocab['<start>'] and idx != target_vocab['<end>']])\n",
    "            target_text = ''.join([target_vocab_inv[idx] for idx in decoder_target_data_test[i] if idx != 0 and idx != target_vocab['<start>'] and idx != target_vocab['<end>']])\n",
    "            input_texts.append(input_text)\n",
    "            target_texts.append(target_text)\n",
    "\n",
    "            #get input and target tokens\n",
    "            input_tokens = [target_vocab_inv[idx] for idx in encoder_input_data_test[i] if idx != 0]\n",
    "            target_tokens = [target_vocab_inv[idx] for idx in decoder_target_data_test[i] if idx != 0]\n",
    "            input_tokens_list.append(input_tokens)\n",
    "            target_tokens_list.append(target_tokens)\n",
    "\n",
    "\n",
    "        # 5. Save predictions\n",
    "        np.save('test_predictions.npy', predictions)\n",
    "\n",
    "        # 6. Print sample predictions\n",
    "        print(\"\\nSample Predictions on Test Data:\")\n",
    "        for i in range(5):  # Print the first 5 predictions\n",
    "            print(f\"Input:  {input_texts[i]}\")\n",
    "            print(f\"Target: {target_texts[i]}\")\n",
    "            print(f\"Predicted: {predictions[i]}\")\n",
    "\n",
    "        # 7.  Visualize Attention Heatmaps for 9 inputs\n",
    "        print(\"\\nGenerating Attention Heatmaps...\")\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "            visualize_attention(input_texts[i], predictions[i], attention_weights[i], input_tokens_list[i], target_tokens_list[i])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging the interactive attention map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T20:33:23.617709Z",
     "iopub.status.busy": "2025-05-20T20:33:23.616898Z",
     "iopub.status.idle": "2025-05-20T20:33:30.721732Z",
     "shell.execute_reply": "2025-05-20T20:33:30.721184Z",
     "shell.execute_reply.started": "2025-05-20T20:33:23.617673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "html_content=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\" />\n",
    "  <title>Attention Visualization</title>\n",
    "  <style>\n",
    "    body {\n",
    "      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "      background: #f9f9fb;\n",
    "      color: #333;\n",
    "      padding: 2em;\n",
    "      line-height: 1.6;\n",
    "    }\n",
    "\n",
    "    h2 {\n",
    "      color: #444;\n",
    "      margin-bottom: 0.5em;\n",
    "    }\n",
    "\n",
    "    .card {\n",
    "      background: #fff;\n",
    "      border-radius: 12px;\n",
    "      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
    "      padding: 1.5em;\n",
    "      margin-bottom: 2em;\n",
    "      transition: transform 0.2s ease;\n",
    "    }\n",
    "\n",
    "    .card:hover {\n",
    "      transform: translateY(-4px);\n",
    "    }\n",
    "\n",
    "    .token-container {\n",
    "      margin-top: 1em;\n",
    "      margin-bottom: 1.2em;\n",
    "    }\n",
    "\n",
    "    .label {\n",
    "      font-weight: bold;\n",
    "      margin-bottom: 0.3em;\n",
    "      display: block;\n",
    "    }\n",
    "\n",
    "    .token {\n",
    "      display: inline-block;\n",
    "      margin: 0.1em 0.2em;\n",
    "      padding: 0.4em 0.6em;\n",
    "      border-radius: 6px;\n",
    "      transition: background-color 0.3s ease;\n",
    "    }\n",
    "\n",
    "    .source-token {\n",
    "      background-color: #f1f1f6;\n",
    "      font-weight: 500;\n",
    "    }\n",
    "\n",
    "    .target-token {\n",
    "      background-color: #dcefff;\n",
    "      cursor: pointer;\n",
    "      font-weight: bold;\n",
    "    }\n",
    "\n",
    "    .target-token:hover {\n",
    "      background-color: #b3e5fc;\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "  <h1>Attention Visualization</h1>\n",
    "\n",
    "  <div id=\"visualizations\"></div>\n",
    "\n",
    "  <script>\n",
    "    const dataset = [\n",
    "      {\n",
    "        source_tokens: ['<sos>', 'k', 'a', 'n', 'd', 'a', 'l', 'a', '<eos>'],\n",
    "        target_tokens: ['&#x0915;', '&#x093E;', '&#x0902;', '&#x0921;', '&#x0932;', '&#x093E;'],\n",
    "        attention: [\n",
    "          [0.0, 0.899, 0.043, 0.052, 0.005, 0.0, 0.0, 0.0, 0.0],\n",
    "          [0.0, 0.0, 0.0, 0.573, 0.426, 0.0, 0.0, 0.0, 0.0],\n",
    "          [0.0, 0.0, 0.0, 0.152, 0.576, 0.033, 0.238, 0.0, 0.0],\n",
    "          [0.0, 0.0, 0.0, 0.004, 0.229, 0.168, 0.526, 0.056, 0.017],\n",
    "          [0.0, 0.0, 0.0, 0.0, 0.006, 0.051, 0.863, 0.040, 0.040],\n",
    "          [0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.009, 0.438, 0.551]\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        source_tokens: ['<sos>', 'a', 'n', 'u', 's', 'u', 'y', 'a', '<eos>'],\n",
    "        target_tokens: ['&#x0905;', '&#x0928;', '&#x0941;', '&#x0938;', '&#x0942;', '&#x092F;', '&#x093E;'],\n",
    "        attention: [\n",
    "          [0.0, 0.77, 0.112, 0.100, 0.017, 0.0, 0.0, 0.0, 0.0],\n",
    "          [0.0, 0.0, 0.596, 0.264, 0.140, 0.0, 0.0, 0.0, 0.0],\n",
    "          [0.0, 0.0, 0.048, 0.554, 0.363, 0.027, 0.008, 0.0, 0.0],\n",
    "          [0.0, 0.0, 0.0, 0.009, 0.125, 0.612, 0.240, 0.003, 0.012],\n",
    "          [0.0, 0.0, 0.0, 0.001, 0.005, 0.497, 0.417, 0.009, 0.071],\n",
    "          [0.0, 0.0, 0.0, 0.0, 0.0, 0.005, 0.193, 0.507, 0.293],\n",
    "          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.189, 0.808]\n",
    "        ]\n",
    "      }\n",
    "    ];\n",
    "\n",
    "    const visualizations = document.getElementById('visualizations');\n",
    "\n",
    "    dataset.forEach((sample, idx) => {\n",
    "      const card = document.createElement('div');\n",
    "      card.className = 'card';\n",
    "\n",
    "      const heading = document.createElement('h2');\n",
    "      heading.textContent = `Sample ${idx + 1}`;\n",
    "      card.appendChild(heading);\n",
    "\n",
    "      const sourceContainer = document.createElement('div');\n",
    "      sourceContainer.className = 'token-container';\n",
    "      const srcLabel = document.createElement('span');\n",
    "      srcLabel.className = 'label';\n",
    "      srcLabel.textContent = 'Source Tokens:';\n",
    "      sourceContainer.appendChild(srcLabel);\n",
    "\n",
    "      const sourceSpans = [];\n",
    "      sample.source_tokens.forEach((tok, sIdx) => {\n",
    "        const span = document.createElement('span');\n",
    "        span.textContent = tok;\n",
    "        span.className = 'token source-token';\n",
    "        span.dataset.index = sIdx;\n",
    "        sourceContainer.appendChild(span);\n",
    "        sourceSpans.push(span);\n",
    "      });\n",
    "\n",
    "      const targetContainer = document.createElement('div');\n",
    "      targetContainer.className = 'token-container';\n",
    "      const tgtLabel = document.createElement('span');\n",
    "      tgtLabel.className = 'label';\n",
    "      tgtLabel.textContent = 'Target Tokens (hover to see attention):';\n",
    "      targetContainer.appendChild(tgtLabel);\n",
    "\n",
    "      sample.target_tokens.forEach((tok, tIdx) => {\n",
    "        const span = document.createElement('span');\n",
    "        span.className = 'token target-token';\n",
    "        span.innerHTML = tok;\n",
    "\n",
    "        span.addEventListener('mouseover', () => {\n",
    "          sourceSpans.forEach((srcSpan, sIdx) => {\n",
    "            const weight = sample.attention[tIdx][sIdx];\n",
    "            srcSpan.style.backgroundColor = `rgba(255, 215, 0, ${weight})`;\n",
    "          });\n",
    "        });\n",
    "\n",
    "        span.addEventListener('mouseout', () => {\n",
    "          sourceSpans.forEach(s => {\n",
    "            s.style.backgroundColor = '#f1f1f6';\n",
    "          });\n",
    "        });\n",
    "\n",
    "        targetContainer.appendChild(span);\n",
    "      });\n",
    "\n",
    "      card.appendChild(sourceContainer);\n",
    "      card.appendChild(targetContainer);\n",
    "      visualizations.appendChild(card);\n",
    "    });\n",
    "  </script>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\"\"\"\n",
    "wandb_project = \"dakshina-transliteration\"\n",
    "with wandb.init(project=wandb_project, name=\"attention_final_new2\") as run:\n",
    "    wandb.log({\"attention_final_new2\": wandb.Html(html_content, inject=False)})"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7445901,
     "sourceId": 11850092,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
